---
title: "Jian et al. paper analysis"
output: word_document
---

```{r}
# questions need double check
# 1. How many times repeaded for hist data?

```

# Introduction

This vignette goes through the basic steps of the Jian et al. paper analysis, demonstrating some of the features of the `urbankfs` R package along the way.

# Setup

Load packages.

```{r}
library(dplyr)
library(forcats)
library(tidyr)
library(modelr)
library(purrr)
library(ggplot2)
# theme_bw()
library(cowplot)
library(urbankfs)
# devtools::install(here::here())
requireNamespace("randomForest", quietly = TRUE)
requireNamespace("here", quietly = TRUE)
```

Load the _full_ set of fitted models.
Because it is large (>100MB), this file is not distributed with the package.
To obtain it, either download from OSF (via `urbankfs::download_jian_fits`) or re-generate it with the `scripts/fit_models.R` script.

```{r}
# download_jian_fits(here::here("extdata/fitted_models.rda"))
load(here::here("extdata", "fitted_models.rda"))
```

# Test and training data predictions

Generate neural network and random forest predictions for the training and test data.
`randomForest` provides a `predict` method for the `randomForest` S3 class.
`urbankfs` defines a custom `predict` method for its neural network fits that is a thin wrapper around `neuralnet::compute` and which also undoes the scaling that happens during fitting.

```{r}
pred <- fitted_models %>%
  select(sample, train_data, test_data, model_type, model_fit) %>%
  gather(data_type, data, train_data, test_data) %>%
  mutate(
    predicted = map2(model_fit, data, predict),
    model_type = fct_recode(model_type, !!!pretty_model_types())
  )
```

Fit a linear model, `observed ~ predicted`, for each bootstrapped sample, and extract the coefficients and R^2^.

```{r}
pred_fits <- pred %>%
  filter(data_type == "test_data") %>%
  unnest(data, predicted) %>%
  select(sample, model_type, observed = Unsaturated_K2cm_cmhr, predicted) %>%
  group_by(sample, model_type) %>%
  summarize(fit = list(lm(observed ~ predicted))) %>%
  ungroup() %>%
  mutate(
    coefficients = map(fit, coefficients),
    slope = map_dbl(coefficients, 2),
    intercept = map_dbl(coefficients, 1),
    r2 = map_dbl(fit, ~summary(.)[["adj.r.squared"]])
  )
```

Use the linear model fits from above to generate a range of predictions of the observed data.
This is mostly for plotting the linear 1:1 fits in subsequent steps.

```{r}
obs <- tibble(
  predicted = fitted_models %>%
    unnest(train_data) %>%
    pull(Unsaturated_K2cm_cmhr) %>%
    seq_range(20)
)

pred_lm <- pred_fits %>%
  mutate(xpred = list(obs),
         lmpred = map2(fit, xpred, predict)) %>%
  unnest(xpred, lmpred) %>%
  group_by(model_type, predicted) %>%
  summarize_at(vars(lmpred), list(
    mean = mean,
    sd = sd,
    lo = ~quantile(., 0.1),
    hi = ~quantile(., 0.9)
  ))
```

Summarize the neural network and random forest model predictions at each point.
These will be drawn as points with horizontal error bars.

```{r}
pred_summary <- pred %>%
  filter(data_type == "test_data") %>%
  unnest(data, predicted) %>%
  group_by(model_type, observed = Unsaturated_K2cm_cmhr) %>%
  summarize_at(vars(predicted), list(
    mean = mean,
    sd = sd,
    lo = ~quantile(., 0.1),
    hi = ~quantile(., 0.9),
    n = length
  ))
```

Draw the observed vs. predicted scatter plot, with true 1:1 line (dashed) and the bootstrapped linear regression (blue shaded region).

```{r fig-regression, fig.cap = fig_regression_cap}
fig_regression_cap <- paste0(
  "Observed vs. predicted regression for neural network and random forest models. ",
  "Dashed line is the 1:1 fit, and blue shaded region is the observed ~ predicted regression."
)

facet_title = c("Neural network (no rock)" = "(a) ANN-no-rock", "Neural network (with rock)" = "(b) ANN-with-rock"
                   ,"RandomForest (no rock, no type)" = "(c) RF-no-rock-no-structure"
                   ,"RandomForest (with rock, no type)" = "(d) RF-with-rock-no-structure"
                   ,"RandomForest (no rock, with type)" = "(e) RF-no-rock-with-structure"
                   ,"RandomForest (with rock, with type)" = "(f) RF-with-rock-with-structure")

ggplot() +
  aes(x = predicted, y = mean) +
  geom_point(aes(y = observed, x = mean),
             data = pred_summary,
             size = 0.5) +
  geom_errorbarh(aes(y = observed, xmin = lo, xmax = hi, x = NULL),
                 data = pred_summary,
                 color = "gray40",
                 size = 0.5) +
  geom_ribbon(
    data = pred_lm,
    aes(ymin = lo, ymax = hi, y = NULL),
    alpha = 0.5,
    fill = "lightblue"
  ) +
  geom_line(aes(y = mean), data = pred_lm) +
  geom_abline(linetype = "dashed") +
  facet_wrap(model_type~., ncol = 2
             , labeller = as_labeller(facet_title) ) +
  labs(x = expression('Predicted K'[fs] ~ (cm ~ hr^{-1})),
       y = expression('Observed K'[fs] ~ (cm ~ hr^{-1}))) +
  theme_cowplot()


ggsave("Figure4.jpg", width = 8, height = 8, dpi = 300, units = "in")
```




Histogram of correlation coefficients for the training and testing data.

```{r fig-correlation, fig.cap = fig_correlation_cap}
fig_correlation_cap <- paste0(
  "Histogram of correlation coefficients for the training and testing data."
)
pred %>%
  unnest(data, predicted) %>%
  mutate(data_type = fct_inorder(data_type) %>% fct_recode(
    "Training" = "test_data",
    "Testing" = "train_data"
  )) %>%
  group_by(model_type, sample, data_type) %>%
  summarize(corr = cor(predicted, Unsaturated_K2cm_cmhr, method = "spearman")) %>%
  ggplot() +
  aes(x = corr) +
  geom_density() +
  facet_grid(vars(model_type), vars(data_type)) +
  labs(x = "Correlation between prediction and data") +
  theme_cowplot()
```

# Urban data predictions

Model predictions for Urban data.
First, load the data.

```{r}
histdata <- read.csv(here::here("extdata/UrbanSoilK_V3.csv")) %>%
  as_tibble() %>%
  mutate(Top_Type = factor(Top_Type, soil_type_levels())) %>%
  normalize_soil_pct_data(add_rock = TRUE)
```

Generate bootstrapped predictions for the data.
`urbankfs` makes this easy with the `predict_bootstrap` function, which also has `summary` method for quickly generating tidy outputs.

```{r}
hist_predict <- predict_bootstrap(histdata, fitted_models)
hist_summary <- summary(hist_predict)
hist_summary
```

How well does it do?

```{r fig-urbandata, fig.cap = fig_urbandata_cap}
fig_urbandata_cap <- paste0(
  "Predicted vs. observed plot for urban data. ",
  "Dashed line is the 1:1 fit, and blue line with grey shading is a `observed ~ predicted` linear fit."
)
histdata %>%
  left_join(hist_summary, by = c("Percent_Sand", "Percent_Silt", "Percent_Clay",
                                 "Top_Type")) %>%
  ggplot() +
  aes(x = mean, xmin = q050, xmax = q950, y = Ksat) +
  geom_errorbarh(color = "grey50", size = 0.5) +
  geom_point(size = 0.7) +
  geom_smooth(method = "lm", color = "blue") +
  geom_abline(linetype = "dashed") +
  facet_wrap(model_type~., ncol = 2
             , labeller = as_labeller(facet_title) 
             ) +
  labs(x = expression("Predicted K"[fs] ~ (cm ~ hr^-1)),
       y = expression("Observed K"[fs] ~ (cm ~ hr^-1))) +
  theme_cowplot() +
  coord_cartesian(xlim = c(0, 35))

# ggsave("Figure5.jpg", width = 8, height = 8, dpi = 300, units = "in")
```


```{r}
# summary for Table 1
min(data_structure$Ksat_cmhr)
histdata %>%
  left_join(hist_summary, by = c("Percent_Sand", "Percent_Silt", "Percent_Clay",
                                 "Top_Type")) %>% select(Percent_Sand, Percent_Silt, Percent_Clay, Ksat, Ksat_Rosseta, mean, model_type)
```


```{r}
# summary for Table 2
pred_summary$mean <- ifelse(pred_summary$mean < 0, 0.001, pred_summary$mean)
pred_summary %>% mutate(S_M = observed - mean) -> pred_summary
var_modelType <- unique(pred_summary$model_type)

evaluation <- function () {
  results <- data.frame()
  for (i in 1:length(var_modelType)) {
    pred_summary %>% filter(model_type == var_modelType[i]) -> subdata
    SLR <- lm(observed ~ mean, data = subdata)
    inter <- summary(SLR)$coefficients[1,1] %>% round(3)
    slope <- summary(SLR)$coefficients[2,1] %>% round(3)
    r2 <- summary(SLR)$adj.r.squared %>% round(3)
    # other model evaluation matric
    E <- (sum(subdata$S_M) / length(subdata$S_M)) %>% round(3)
    d <-  (1- sum(subdata$S_M^2)/sum((abs(subdata$mean-mean(subdata$observed))+abs(subdata$observed-mean(subdata$observed)))^2)) %>% round(3)
    # EF <- 1- sum(subdata$S_M^2)/sum((subdata$observed-mean(subdata$observed))^2)
    RMSE <- (sum(subdata$S_M^2)/length(subdata$S_M))^0.5 %>% round(3)
    p <- t.test(subdata$S_M)$p.value %>% round(3)
    
    results <- rbind(results, data.frame(var_modelType[i], inter, slope, r2, E, d, RMSE, p) )
  }
  return(results)
}

# getwd()
results <- evaluation()
# write.csv(results, "results.csv", row.names = F)
```


```{r}
# summary for Table 3
hist_summary$mean <- ifelse(hist_summary$mean < 0, 0.001, hist_summary$mean)

histdata %>%
  left_join(hist_summary, by = c("Percent_Sand", "Percent_Silt", "Percent_Clay",
                                 "Top_Type")) %>% select(Percent_Sand, Percent_Silt, Percent_Clay, Ksat, Ksat_Rosseta, mean, model_type) -> hist_sum

hist_sum %>% mutate(S_M = Ksat - mean) -> hist_sum
var_modelType <- unique(hist_sum$model_type)

evaluation2 <- function () {
  results <- data.frame()
  for (i in 1:length(var_modelType)) {
    hist_sum %>% filter(model_type == var_modelType[i]) -> subdata
    SLR <- lm(Ksat ~ mean, data = subdata)
    inter <- summary(SLR)$coefficients[1,1] %>% round(3)
    slope <- summary(SLR)$coefficients[2,1] %>% round(3)
    r2 <- summary(SLR)$adj.r.squared %>% round(3)
    # other model evaluation matric
    E <- (sum(subdata$S_M) / length(subdata$S_M)) %>% round(3)
    d <-  (1- sum(subdata$S_M^2)/sum((abs(subdata$mean-mean(subdata$Ksat))+abs(subdata$Ksat-mean(subdata$Ksat)))^2)) %>% round(3)
    # EF <- 1- sum(subdata$S_M^2)/sum((subdata$Ksat-mean(subdata$Ksat))^2)
    RMSE <- (sum(subdata$S_M^2)/length(subdata$S_M))^0.5 %>% round(3)
    p <- t.test(subdata$S_M)$p.value %>% round(3)
    
    results <- rbind(results, data.frame(var_modelType[i], inter, slope, r2, E, d, RMSE, p) )
  }
  return(results)
}

# getwd()
results2 <- evaluation2()
write.csv(results2, "results2.csv", row.names = F)
```



