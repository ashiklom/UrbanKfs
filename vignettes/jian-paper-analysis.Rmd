---
title: "Jian et al. paper analysis"
output: word_document
---

```{r}
# questions need double check
# 1. How many times repeaded for hist data?

```

# Introduction

This vignette goes through the basic steps of the Jian et al. paper analysis, demonstrating some of the features of the `urbankfs` R package along the way.

# Setup

Load packages.

```{r setup}
library(dplyr)
library(forcats)
library(tidyr)
library(modelr)
library(purrr)
library(ggplot2)
library(cowplot)
library(urbankfs)
# install.packages("here")
# install.packages("randomForest")
library(devtools)
requireNamespace("here", quietly = TRUE)
# devtools::install(here::here())
requireNamespace("randomForest", quietly = TRUE)

```

Load the _full_ set of fitted models.
Because it is large (>100MB), this file is not distributed with the package.
To obtain it, either download from OSF (via `urbankfs::download_jian_fits`) or re-generate it with the `scripts/fit_models.R` script.

```{r load-models}
# download_jian_fits(here::here("extdata/fitted_models.rda"))
load(here::here("extdata", "fitted_models.rda"))
# load("extdata/fitted_models.rda")
```

# Urban data predictions

Model predictions for Urban data.
First, load the data.
Note that the urban soil data does not report rock percentage.

```{r load-urban-data}
histdata <- read.csv(here::here("extdata/UrbanSoilK_V3.csv")) %>%
  as_tibble() %>%
  mutate(Top_Type = factor(Top_Type, soil_type_levels())) %>%
  normalize_soil_pct_data(add_rock = FALSE)
```

Generate bootstrapped predictions for the data.
`urbankfs` makes this easy with the `predict_bootstrap` function, which also has `summary` method for quickly generating tidy outputs.
Note that we can only use models without rock percentage as a predictor because it is not reported.

```{r predict-urban-data}
fitted_models_norock <- fitted_models %>%
  left_join(model_rock_type, "model_type") %>%
  filter(!use_rock)
hist_predict <- predict_bootstrap(histdata, fitted_models_norock)
hist_summary <- summary(hist_predict)
hist_summary
```


# Test and training data predictions

Generate neural network and random forest predictions for the training and test data.
`randomForest` provides a `predict` method for the `randomForest` S3 class.
`urbankfs` defines a custom `predict` method for its neural network fits that is a thin wrapper around `neuralnet::compute` and which also undoes the scaling that happens during fitting.

```{r predict}
model_rock_type <- tribble(
  ~model_type, ~use_rock, ~top_type,
  "ann", FALSE, FALSE,
  "annr", TRUE, FALSE,
  "rf1", FALSE, FALSE,
  "rf1r", TRUE, FALSE,
  "rf2", FALSE, TRUE,
  "rf2r", TRUE, TRUE
)
pred <- fitted_models %>%
  select(sample, train_data, test_data, model_type, model_fit) %>%
  gather(data_type, data, train_data, test_data) %>%
  left_join(model_rock_type, by = "model_type") %>%
  mutate(
    # Subset the data so that it first the needs of the model
    data_prep = pmap(list(data, use_rock, top_type), prepare_data),
    # Actually run the predictions
    predicted = map2(model_fit, data_prep, predict),
    # Make the model_type labels plot-ready
    model_type = fct_recode(model_type, !!!pretty_model_types())
  )
```



Fit a linear model, `observed ~ predicted`, for each bootstrapped sample, and extract the coefficients and R^2^.

```{r fit-line-to-pred}
pred_fits <- pred %>%
  filter(data_type == "test_data") %>%
  unnest(data_prep, predicted) %>%
  select(sample, model_type, observed = Unsaturated_K2cm_cmhr, predicted) %>%
  group_by(sample, model_type) %>%
  summarize(fit = list(lm(observed ~ predicted))) %>%
  ungroup() %>%
  mutate(
    coefficients = map(fit, coefficients),
    slope = map_dbl(coefficients, 2),
    intercept = map_dbl(coefficients, 1),
    r2 = map_dbl(fit, ~summary(.)[["adj.r.squared"]])
  )
```

Use the linear model fits from above to generate a range of predictions of the observed data.
This is mostly for plotting the linear 1:1 fits in subsequent steps.

```{r predict-observed}
obs <- tibble(
  predicted = fitted_models %>%
    unnest(train_data) %>%
    pull(Unsaturated_K2cm_cmhr) %>%
    seq_range(20)
)

pred_lm <- pred_fits %>%
  mutate(xpred = list(obs),
         lmpred = map2(fit, xpred, predict)) %>%
  unnest(xpred, lmpred) %>%
  group_by(model_type, predicted) %>%
  summarize_at(vars(lmpred), list(
    mean = mean,
    sd = sd,
    lo = ~quantile(., 0.1),
    hi = ~quantile(., 0.9)
  ))
```

Summarize the neural network and random forest model predictions at each point.
These will be drawn as points with horizontal error bars.

```{r summarize-point-predictions}
pred_summary <- pred %>%
  filter(data_type == "test_data") %>%
  unnest(data_prep, predicted) %>%
  group_by(model_type, observed = Unsaturated_K2cm_cmhr) %>%
  summarize_at(vars(predicted), list(
    mean = mean,
    sd = sd,
    lo = ~quantile(., 0.1),
    hi = ~quantile(., 0.9),
    n = length
  ))
```

Draw the observed vs. predicted scatter plot, with true 1:1 line (dashed) and the bootstrapped linear regression (blue shaded region).

```{r fig-regression, fig.cap = fig_regression_cap, fig.width=4, fig.height=6}
fig_regression_cap <- paste0(
  "Observed vs. predicted regression for neural network and random forest models. ",
  "Dashed line is the 1:1 fit, and blue shaded region is the observed ~ predicted regression."
)

facet_title = c("Neural network (no rock)" = "(a) ANN-no-structure"
                   ,"RandomForest (no rock, no type)" = "(b) RF-no-structure"
                   ,"RandomForest (no rock, with type)" = "(c) RF-with-structure"
                   )

pred_summary %>% filter(model_type %in% c("Neural network (no rock)", "RandomForest (no rock, no type)", "RandomForest (no rock, with type)")) %>% 
  ggplot(aes(x = mean, y = observed)) +  geom_point(size = 0.5) +
  facet_wrap(model_type~., ncol = 1
             , labeller = as_labeller(facet_title)
             ) +
  
  geom_errorbarh(aes(y = observed, xmin = lo, xmax = hi, x = NULL),
                 color = "gray40",
                 size = 0.5) +
  # geom_ribbon(
  #   data = pred_lm %>% filter(model_type %in% c("Neural network (no rock)", "RandomForest (no rock, no type)", "RandomForest (no rock, with type)")),
  #   aes(ymin = lo, ymax = hi, y = NULL),
  #   alpha = 0.5,
  #   fill = "lightblue"
  # ) +
  geom_abline(linetype = "dashed") +
  geom_smooth(method = "lm", color = "blue", se = T, fill="lightblue", alpha = 0.5, lwd = 0.5) +
  # geom_line(aes(y = observed), data = pred_lm %>% 
  #             filter(model_type %in% c("Neural network (no rock)", "RandomForest (no rock, no type)", "RandomForest (no rock, with type)")) ) +
  
  
  labs(x = expression('Predicted K'[fs] ~ (cm ~ hr^{-1})),
       y = expression('Observed K'[fs] ~ (cm ~ hr^{-1}))) +
  theme_cowplot() -> p1


# evaluation dataset (n=20)
facet_title = c("Neural network (no rock)" = "(a) ANN-no-structure"
                   ,"RandomForest (no rock, no type)" = "(b) RF-no-structure"
                   ,"RandomForest (no rock, with type)" = "(c) RF-with-structure"
                   )
fig_urbandata_cap <- paste0(
  "Predicted vs. observed plot for urban data. ",
  "Dashed line is the 1:1 fit, and blue line with grey shading is a `observed ~ predicted` linear fit."
)


histdata %>%
  left_join(hist_summary, by = c("Percent_Sand", "Percent_Silt", "Percent_Clay",
                                 "Top_Type")) %>%
  ggplot() +
  aes(x = mean, xmin = q050, xmax = q950, y = Ksat) +
  geom_errorbarh(color = "grey50", size = 0.5) +
  geom_point(size = 0.7) +
  geom_smooth(method = "lm", color = "blue", alpha = 0.5, lwd = 0.5, fill = "lightblue") +
  geom_abline(linetype = "dashed") +
  facet_wrap(model_type~., ncol = 1
             , labeller = as_labeller(facet_title) 
             ) +
  labs(x = expression("Predicted K"[fs] ~ (cm ~ hr^-1)),
       y = expression("Observed K"[fs] ~ (cm ~ hr^-1))) +
  theme_cowplot() +
  coord_cartesian(xlim = c(0, 35)) -> p2

plot_grid(p1)

ggsave("Figure2.jpg", width = 4, height = 6, dpi = 300, units = "in")
```


How well does it do?

```{r fig-urbandata, fig.cap = fig_urbandata_cap, fig.width=4, fig.height=6}
print(p2)
ggsave("Figure3.jpg", width = 4, height = 6, dpi = 300, units = "in")
```


```{r model test}
pred_summary %>% filter(model_type %in% c("Neural network (no rock)")) %>% 
  ggplot() +
  aes(x = predicted, y = mean) +
  geom_point(aes(y = observed, x = mean),
             size = 0.5)

subdata <- pred_summary %>% filter(model_type %in% c("Neural network (no rock)")) 

```



Histogram of correlation coefficients for the training and testing data.

```{r fig-correlation, fig.cap = fig_correlation_cap}
fig_correlation_cap <- paste0(
  "Histogram of correlation coefficients for the training and testing data."
)
pred %>%
  unnest(data_prep, predicted) %>%
  mutate(data_type = fct_inorder(data_type) %>% fct_recode(
    "Training" = "test_data",
    "Testing" = "train_data"
  )) %>%
  group_by(model_type, sample, data_type) %>%
  summarize(corr = cor(predicted, Unsaturated_K2cm_cmhr, method = "spearman")) %>%
  ggplot() +
  aes(x = corr) +
  geom_density() +
  facet_grid(vars(model_type), vars(data_type)) +
  labs(x = "Correlation between prediction and data") +
  theme_cowplot()
```






```{r table-1-summary}
# summary for Table 1
# ANS: This object doesn't exist in this Rmd document
## min(data_structure$Ksat_cmhr)
histdata %>%
  left_join(hist_summary, by = c("Percent_Sand", "Percent_Silt", "Percent_Clay",
                                 "Top_Type")) %>% select(Percent_Sand, Percent_Silt, Percent_Clay, Ksat, Ksat_Rosseta, mean, model_type) 
# %>% spread(model_type,mean)
```


```{r table-2-summary}
# summary for Table 2
pred_summary$mean <- ifelse(pred_summary$mean < 0, 0.001, pred_summary$mean)
pred_summary %>% mutate(S_M = observed - mean) -> pred_summary
var_modelType <- c("Neural network (no rock)", "RandomForest (no rock, no type)", "RandomForest (no rock, with type)")

evaluation <- function () {
  results <- data.frame()
  for (i in 1:length(var_modelType)) {
    pred_summary %>% filter(model_type == var_modelType[i]) -> subdata
    SLR <- lm(observed ~ mean, data = subdata)
    inter <- summary(SLR)$coefficients[1,1] %>% round(3)
    slope <- summary(SLR)$coefficients[2,1] %>% round(3)
    r2 <- summary(SLR)$adj.r.squared %>% round(3)
    # other model evaluation matric
    E <- (sum(subdata$S_M) / length(subdata$S_M)) %>% round(3)
    d <-  (1- sum(subdata$S_M^2)/sum((abs(subdata$mean-mean(subdata$observed))+abs(subdata$observed-mean(subdata$observed)))^2)) %>% round(3)
    # EF <- 1- sum(subdata$S_M^2)/sum((subdata$observed-mean(subdata$observed))^2)
    RMSE <- (sum(subdata$S_M^2)/length(subdata$S_M))^0.5 %>% round(3)
    p <- t.test(subdata$S_M)$p.value %>% round(3)
    
    results <- rbind(results, data.frame(var_modelType[i], inter, slope, r2, E, d, RMSE, p) )
  }
  return(results)
}

# getwd()
results <- evaluation()
write.csv(results, "results.csv", row.names = F)
results
```


```{r}
i = 3
pred_summary %>% filter(model_type == var_modelType[i]) -> subdata
SLR <- lm(observed ~ mean, data = subdata)
subdata %>% ggplot(aes(x = mean, y = observed)) + geom_point() + geom_smooth(method = "lm") +
  geom_abline(h = 0, v = 0)
```


```{r table-3-summary}
# summary for Table 3
hist_summary$mean <- ifelse(hist_summary$mean < 0, 0.001, hist_summary$mean)

histdata %>%
  left_join(hist_summary, by = c("Percent_Sand", "Percent_Silt", "Percent_Clay",
                                 "Top_Type")) %>% select(Percent_Sand, Percent_Silt, Percent_Clay, Ksat, Ksat_Rosseta, mean, model_type) -> hist_sum

hist_sum %>% mutate(S_M = Ksat - mean) -> hist_sum
var_modelType <- unique(hist_sum$model_type)

evaluation2 <- function () {
  results <- data.frame()
  for (i in 1:length(var_modelType)) {
    hist_sum %>% filter(model_type == var_modelType[i]) -> subdata
    SLR <- lm(Ksat ~ mean, data = subdata)
    inter <- summary(SLR)$coefficients[1,1] %>% round(3)
    slope <- summary(SLR)$coefficients[2,1] %>% round(3)
    r2 <- summary(SLR)$adj.r.squared %>% round(3)
    # other model evaluation matric
    E <- (sum(subdata$S_M) / length(subdata$S_M)) %>% round(3)
    d <-  (1- sum(subdata$S_M^2)/sum((abs(subdata$mean-mean(subdata$Ksat))+abs(subdata$Ksat-mean(subdata$Ksat)))^2)) %>% round(3)
    # EF <- 1- sum(subdata$S_M^2)/sum((subdata$Ksat-mean(subdata$Ksat))^2)
    RMSE <- (sum(subdata$S_M^2)/length(subdata$S_M))^0.5 %>% round(3)
    p <- t.test(subdata$S_M)$p.value %>% round(3)
    
    results <- rbind(results, data.frame(var_modelType[i], inter, slope, r2, E, d, RMSE, p) )
  }
  return(results)
}

# getwd()
results2 <- evaluation2()
write.csv(results2, "results2.csv", row.names = F)
results2
```



